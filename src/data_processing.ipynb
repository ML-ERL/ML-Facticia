{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image and text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and processor form local storage\n"
     ]
    }
   ],
   "source": [
    "# classes: 0-Caption 1-Handwritting 2-Image 3-Text\n",
    "\n",
    "from image_processor import extract_image\n",
    "from text_processor import extract_text\n",
    "from clip import CLIPInstance\n",
    "from ultralytics import YOLO\n",
    "from data_format import DataFormat\n",
    "\n",
    "import json, os\n",
    "\n",
    "data_path = \"../dataset/facticia_3_2/\"\n",
    "export_path = \"../dataset/results/\"\n",
    "\n",
    "filename = \"4c76a3e4-ohcbh_cf_erl8_204\"\n",
    "\n",
    "image_path = f\"{data_path}/images/{filename}.jpg\"\n",
    "\n",
    "clip_model = CLIPInstance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danieltm/anaconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647329220/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/danieltm/Documents/MATCOM/4A 1S/ML/ML-Facticia/src/../dataset/facticia_3_2/images/4c76a3e4-ohcbh_cf_erl8_204.jpg: 1024x704 190.1ms\n",
      "Speed: 7.7ms preprocess, 190.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 704)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"detection/best.pt\")\n",
    "\n",
    "result = model(image_path)\n",
    "\n",
    "obb = result[0].obb\n",
    "\n",
    "xywhr = obb.xywhr\n",
    "cls = obb.cls\n",
    "\n",
    "data = []\n",
    "\n",
    "# # Verify if the export folder exists\n",
    "# if not os.path.exists(f\"{export_path}/{filename}\"):\n",
    "\n",
    "# Create folder to store crops\n",
    "os.makedirs(f\"{export_path}/{filename}\", exist_ok=True)\n",
    "\n",
    "# Save crops and create metadata\n",
    "for i in range(len(xywhr)):\n",
    "    data.append(DataFormat(f\"{filename}_{i}\", xywhr[i], cls[i]))\n",
    "    image = extract_image(image_path, xywhr[i])\n",
    "\n",
    "    image.save(f\"{export_path}/{filename}/{filename}_{i}.jpg\")\n",
    "\n",
    "for d in data:\n",
    "    if d.type == 3:\n",
    "        d.text = extract_text(f\"{export_path}/{filename}/{d.filename}.jpg\")\n",
    "    \n",
    "\n",
    "# Create json file to store crops metadata\n",
    "with open(f\"{export_path}/{filename}/{filename}.json\", \"w\") as f:\n",
    "    json.dump({d.filename: d.to_dict() for d in data}, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.074274     0.36429     0.55656   0.0047802  0.00010222]]\n",
      "['LA REMODELACION\\nDE LA HABANA\\n', 'Vista Genreal de la Alameda de Paula,\\ndespués de su restauración.\\n', 'Vista general de la Plaza de Agua Dulce.\\n', 'Vista del Paso Superior construido por\\n\\nla Dirección Ceneral de Ingemieros del\\n\\nMinisterio de Obras Públicas en la barriada\\nde Luyano.\\n', '- a a\\nSN A a\\n']\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(export_path)\n",
    "\n",
    "for filename in images:\n",
    "    json_file = f\"{export_path}/{filename}/{filename}.json\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    crops = []\n",
    "    for value in data.values():\n",
    "        crop_name = value[\"filename\"]\n",
    "        crop_path = f\"{export_path}/{filename}/{crop_name}.jpg\"\n",
    "        crop_type = value[\"type\"]\n",
    "        crop_text = value[\"text\"]\n",
    "        crop_xywhr = [float(value[\"x\"]), float(value[\"y\"]), float(value[\"w\"]), float(value[\"h\"]), float(value[\"r\"])]    \n",
    "        crop = DataFormat(crop_name, crop_xywhr, crop_type, crop_text)\n",
    "        \n",
    "        crops.append(crop)        \n",
    "        \n",
    "    images = [f\"{export_path}/{filename}/{crop.filename}.jpg\" for crop in crops if crop.type == 2]\n",
    "    texts = [crop.text for crop in crops if crop.type == 3]\n",
    "    \n",
    "    clip_model.get_relation(images[0], texts)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
