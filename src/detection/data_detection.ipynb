{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Osvaldo\\4.1\\Machine Learning\\ML-Facticia\\src\\detection\\img\\4c76a3e4-ohcbh_cf_erl8_204.jpg: 1024x704 109.0ms\n",
      "Speed: 25.1ms preprocess, 109.0ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "OBB ultralytics.engine.results.OBB object with attributes:\n",
      "\n",
      "cls: tensor([2., 3., 3., 3., 3., 0., 3.], device='cuda:0')\n",
      "conf: tensor([0.9334, 0.8690, 0.8336, 0.7779, 0.5658, 0.4952, 0.4116], device='cuda:0')\n",
      "data: tensor([[6.1382e+02, 1.6523e+03, 1.0988e+03, 9.3874e+02, 1.5720e+00, 9.3335e-01, 2.0000e+00],\n",
      "        [5.2947e+02, 3.0486e+02, 5.5782e+02, 1.5084e+02, 3.1299e+00, 8.6900e-01, 3.0000e+00],\n",
      "        [1.4361e+03, 1.6327e+03, 6.3439e+02, 8.8100e+01, 3.1384e+00, 8.3356e-01, 3.0000e+00],\n",
      "        [7.2647e+02, 2.7416e+03, 6.0652e+02, 4.9174e+01, 3.1369e+00, 7.7789e-01, 3.0000e+00],\n",
      "        [7.0098e+02, 8.9207e+02, 6.5998e+02, 1.6620e+02, 3.1396e+00, 5.6575e-01, 3.0000e+00],\n",
      "        [7.2330e+02, 8.9783e+02, 6.7323e+02, 1.7288e+02, 2.7750e-03, 4.9524e-01, 0.0000e+00],\n",
      "        [1.3855e+03, 4.6449e+02, 5.6713e+02, 6.9924e+01, 3.1270e+00, 4.1163e-01, 3.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (3267, 2238)\n",
      "shape: torch.Size([7, 7])\n",
      "xywhr: tensor([[6.1382e+02, 1.6523e+03, 1.0988e+03, 9.3874e+02, 1.5720e+00],\n",
      "        [5.2947e+02, 3.0486e+02, 5.5782e+02, 1.5084e+02, 3.1299e+00],\n",
      "        [1.4361e+03, 1.6327e+03, 6.3439e+02, 8.8100e+01, 3.1384e+00],\n",
      "        [7.2647e+02, 2.7416e+03, 6.0652e+02, 4.9174e+01, 3.1369e+00],\n",
      "        [7.0098e+02, 8.9207e+02, 6.5998e+02, 1.6620e+02, 3.1396e+00],\n",
      "        [7.2330e+02, 8.9783e+02, 6.7323e+02, 1.7288e+02, 2.7750e-03],\n",
      "        [1.3855e+03, 4.6449e+02, 5.6713e+02, 6.9924e+01, 3.1270e+00]], device='cuda:0')\n",
      "xyxy: tensor([[ 143.8027, 1102.3077, 1083.8462, 2202.2617],\n",
      "        [ 249.6999,  226.1803,  809.2416,  383.5305],\n",
      "        [1118.7262, 1587.6250, 1753.4022, 1677.7766],\n",
      "        [ 423.1031, 2715.5801, 1029.8463, 2767.5854],\n",
      "        [ 370.8229,  808.3166, 1031.1327,  975.8184],\n",
      "        [ 386.4443,  810.4579, 1060.1471,  985.2021],\n",
      "        [1101.4353,  425.3959, 1669.5225,  503.5872]], device='cuda:0')\n",
      "xyxyxyxy: tensor([[[ 143.8027, 2201.1494],\n",
      "         [1082.5443, 2202.2617],\n",
      "         [1083.8462, 1103.4198],\n",
      "         [ 145.1046, 1102.3077]],\n",
      "\n",
      "        [[ 249.6999,  232.7027],\n",
      "         [ 251.4636,  383.5305],\n",
      "         [ 809.2416,  377.0082],\n",
      "         [ 807.4779,  226.1803]],\n",
      "\n",
      "        [[1118.7262, 1589.6768],\n",
      "         [1119.0111, 1677.7766],\n",
      "         [1753.4022, 1675.7249],\n",
      "         [1753.1173, 1587.6250]],\n",
      "\n",
      "        [[ 423.1031, 2718.4126],\n",
      "         [ 423.3328, 2767.5854],\n",
      "         [1029.8463, 2764.7529],\n",
      "         [1029.6166, 2715.5801]],\n",
      "\n",
      "        [[ 370.8229,  809.6181],\n",
      "         [ 371.1506,  975.8184],\n",
      "         [1031.1327,  974.5169],\n",
      "         [1030.8048,  808.3166]],\n",
      "\n",
      "        [[1059.6674,  985.2021],\n",
      "         [1060.1471,  812.3261],\n",
      "         [ 386.9240,  810.4579],\n",
      "         [ 386.4443,  983.3339]],\n",
      "\n",
      "        [[1101.4353,  433.6702],\n",
      "         [1102.4556,  503.5872],\n",
      "         [1669.5225,  495.3128],\n",
      "         [1668.5022,  425.3959]]], device='cuda:0')\n",
      "xyxyxyxyn: tensor([[[0.0643, 0.6738],\n",
      "         [0.4837, 0.6741],\n",
      "         [0.4843, 0.3377],\n",
      "         [0.0648, 0.3374]],\n",
      "\n",
      "        [[0.1116, 0.0712],\n",
      "         [0.1124, 0.1174],\n",
      "         [0.3616, 0.1154],\n",
      "         [0.3608, 0.0692]],\n",
      "\n",
      "        [[0.4999, 0.4866],\n",
      "         [0.5000, 0.5136],\n",
      "         [0.7835, 0.5129],\n",
      "         [0.7833, 0.4860]],\n",
      "\n",
      "        [[0.1891, 0.8321],\n",
      "         [0.1892, 0.8471],\n",
      "         [0.4602, 0.8463],\n",
      "         [0.4601, 0.8312]],\n",
      "\n",
      "        [[0.1657, 0.2478],\n",
      "         [0.1658, 0.2987],\n",
      "         [0.4607, 0.2983],\n",
      "         [0.4606, 0.2474]],\n",
      "\n",
      "        [[0.4735, 0.3016],\n",
      "         [0.4737, 0.2486],\n",
      "         [0.1729, 0.2481],\n",
      "         [0.1727, 0.3010]],\n",
      "\n",
      "        [[0.4922, 0.1327],\n",
      "         [0.4926, 0.1541],\n",
      "         [0.7460, 0.1516],\n",
      "         [0.7455, 0.1302]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Preload basic model\n",
    "\n",
    "def cropp_image(image, xywhr):\n",
    "    \"\"\"\n",
    "    Cropp image with given arguments\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, w, h, r = xywhr[0].cpu().numpy()\n",
    "    image.rotate(-r)\n",
    "    cropped_image = image.crop((x - w / 2, y - h / 2, x + w / 2, y + h / 2))\n",
    "    return cropped_image\n",
    "\n",
    "def save_image(image, class_name):\n",
    "    \"\"\"\n",
    "    Save image with given class name\n",
    "    \"\"\"\n",
    "    image.save(f\"{class_name}.png\")\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Load images\n",
    "img = \"./img/\"\n",
    "images = [img + i for i in os.listdir(img) if i.endswith(\".jpg\")]\n",
    "\n",
    "# Create a directory to save processed images\n",
    "processed_dir = \"./processed/\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "for i in os.listdir(img):\n",
    "    if i.endswith(\".jpg\"):\n",
    "        results = model(img + i)\n",
    "        img_cont = 0\n",
    "        os.makedirs(processed_dir + i, exist_ok=True)\n",
    "        for result in results:\n",
    "            img_cont += 1\n",
    "            print(\"OBB\", result.obb)\n",
    "            class_detected = result.obb.cls\n",
    "            xywhr = result.obb.xywhr\n",
    "           \n",
    "           \n",
    "            cropped_image.save(processed_dir + i + \"/cropped\" + str(img_cont) + \".jpg\")\n",
    "            result.show()  # display to screen\n",
    "            result.save(filename=\"result.jpg\")  # save to disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
