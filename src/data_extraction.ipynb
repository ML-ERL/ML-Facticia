{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload basic model\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n-obb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "from dataset_loader import get_dataset_from_file\n",
    "\n",
    "data_path = \"../dataset/facticia_3\"\n",
    "\n",
    "get_dataset_from_file(data_path) # Import dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:51:49,631\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "URI has empty scheme: './ray_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n-obb.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39mdataset, epochs\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m], batch\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m], lr0\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlro\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m analysis \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     19\u001b[0m     train_model,\n\u001b[1;32m     20\u001b[0m     config\u001b[38;5;241m=\u001b[39msearch_space,\n\u001b[1;32m     21\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     22\u001b[0m     resources_per_trial\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m},\n\u001b[1;32m     23\u001b[0m     storage_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ray_output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest config: \u001b[39m\u001b[38;5;124m\"\u001b[39m, analysis\u001b[38;5;241m.\u001b[39mget_best_config(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ray/tune/tune.py:758\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, exp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(experiments):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exp, Experiment):\n\u001b[0;32m--> 758\u001b[0m         experiments[i] \u001b[38;5;241m=\u001b[39m Experiment(\n\u001b[1;32m    759\u001b[0m             name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    760\u001b[0m             run\u001b[38;5;241m=\u001b[39mexp,\n\u001b[1;32m    761\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    762\u001b[0m             time_budget_s\u001b[38;5;241m=\u001b[39mtime_budget_s,\n\u001b[1;32m    763\u001b[0m             config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    764\u001b[0m             resources_per_trial\u001b[38;5;241m=\u001b[39mresources_per_trial,\n\u001b[1;32m    765\u001b[0m             num_samples\u001b[38;5;241m=\u001b[39mnum_samples,\n\u001b[1;32m    766\u001b[0m             storage_path\u001b[38;5;241m=\u001b[39mstorage_path,\n\u001b[1;32m    767\u001b[0m             storage_filesystem\u001b[38;5;241m=\u001b[39mstorage_filesystem,\n\u001b[1;32m    768\u001b[0m             sync_config\u001b[38;5;241m=\u001b[39msync_config,\n\u001b[1;32m    769\u001b[0m             checkpoint_config\u001b[38;5;241m=\u001b[39mcheckpoint_config,\n\u001b[1;32m    770\u001b[0m             trial_name_creator\u001b[38;5;241m=\u001b[39mtrial_name_creator,\n\u001b[1;32m    771\u001b[0m             trial_dirname_creator\u001b[38;5;241m=\u001b[39mtrial_dirname_creator,\n\u001b[1;32m    772\u001b[0m             log_to_file\u001b[38;5;241m=\u001b[39mlog_to_file,\n\u001b[1;32m    773\u001b[0m             export_formats\u001b[38;5;241m=\u001b[39mexport_formats,\n\u001b[1;32m    774\u001b[0m             max_failures\u001b[38;5;241m=\u001b[39mmax_failures,\n\u001b[1;32m    775\u001b[0m             restore\u001b[38;5;241m=\u001b[39mrestore,\n\u001b[1;32m    776\u001b[0m         )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fail_fast \u001b[38;5;129;01mand\u001b[39;00m max_failures \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_failures must be 0 if fail_fast=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ray/tune/experiment/experiment.py:167\u001b[0m, in \u001b[0;36mExperiment.__init__\u001b[0;34m(self, name, run, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, sync_config, checkpoint_config, trial_name_creator, trial_dirname_creator, log_to_file, export_formats, max_failures, restore, local_dir)\u001b[0m\n\u001b[1;32m    164\u001b[0m     name \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mget_experiment_dir_name(run)\n\u001b[1;32m    166\u001b[0m storage_path \u001b[38;5;241m=\u001b[39m storage_path \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_STORAGE_PATH\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context_cls(\n\u001b[1;32m    168\u001b[0m     storage_path\u001b[38;5;241m=\u001b[39mstorage_path,\n\u001b[1;32m    169\u001b[0m     storage_filesystem\u001b[38;5;241m=\u001b[39mstorage_filesystem,\n\u001b[1;32m    170\u001b[0m     sync_config\u001b[38;5;241m=\u001b[39msync_config,\n\u001b[1;32m    171\u001b[0m     experiment_dir_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStorageContext on the DRIVER:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ray/train/_internal/storage.py:444\u001b[0m, in \u001b[0;36mStorageContext.__init__\u001b[0;34m(self, storage_path, experiment_dir_name, sync_config, storage_filesystem, trial_dir_name, current_checkpoint_index)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_checkpoint_index \u001b[38;5;241m=\u001b[39m current_checkpoint_index\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_config \u001b[38;5;241m=\u001b[39m sync_config \u001b[38;5;129;01mor\u001b[39;00m SyncConfig()\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_filesystem, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_fs_path \u001b[38;5;241m=\u001b[39m get_fs_and_path(\n\u001b[1;32m    445\u001b[0m     storage_path, storage_filesystem\n\u001b[1;32m    446\u001b[0m )\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_fs_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_fs_path)\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyncer: Syncer \u001b[38;5;241m=\u001b[39m _FilesystemSyncer(\n\u001b[1;32m    450\u001b[0m     storage_filesystem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_filesystem,\n\u001b[1;32m    451\u001b[0m     sync_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_config\u001b[38;5;241m.\u001b[39msync_period,\n\u001b[1;32m    452\u001b[0m     sync_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_config\u001b[38;5;241m.\u001b[39msync_timeout,\n\u001b[1;32m    453\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ray/train/_internal/storage.py:309\u001b[0m, in \u001b[0;36mget_fs_and_path\u001b[0;34m(storage_path, storage_filesystem)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage_filesystem:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m storage_filesystem, storage_path\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mFileSystem\u001b[38;5;241m.\u001b[39mfrom_uri(storage_path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pyarrow/_fs.pyx:471\u001b[0m, in \u001b[0;36mpyarrow._fs.FileSystem.from_uri\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: URI has empty scheme: './ray_output'"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tunning\n",
    "from ultralytics import YOLO\n",
    "from ray import tune\n",
    "\n",
    "dataset = \"../dataset/data.yaml\"\n",
    "\n",
    "# Define search space\n",
    "search_space = {\n",
    "    \"lr0\": tune.uniform(1e-5, 1e-1),\n",
    "    \"batch\": tune.choice([8, 16, 32]),\n",
    "    \"epochs\": tune.choice([32, 64, 128]), \n",
    "}\n",
    "\n",
    "def train_model(config):\n",
    "    model = YOLO('yolo11n-obb.pt')\n",
    "    model.train(data=dataset, epochs=config['epochs'], batch=config['batch'], lr0=config['lro'])\n",
    "    \n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    resources_per_trial={\"cpu\":4, \"gpu\":1},\n",
    "    storage_path=\"/home/danieltm/Documents/MATCOM/4A 1S/ML/ML-Facticia/src/ray_outpu\"\n",
    ")\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(metric=\"mean_accuracy\", mode=\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 🚀 Python-3.12.2 torch-2.5.1 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4034MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolo11n-obb.pt, data=../dataset/data.yaml, epochs=1, time=None, patience=100, batch=2, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/train12\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    503119  ultralytics.nn.modules.head.OBB              [4, 1, [64, 128, 256]]        \n",
      "YOLO11n-obb summary: 344 layers, 2,662,287 parameters, 2,662,271 gradients\n",
      "\n",
      "Transferred 535/541 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/danieltm/Documents/MATCOM/4A 1S/ML/ML-Facticia/dataset/training/labels.cache... 106 images, 0 backgrounds, 0 corrupt: 100%|██████████| 106/106 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/danieltm/Documents/MATCOM/4A 1S/ML/ML-Facticia/dataset/validation/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/obb/train12/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/obb/train12\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1     0.933G      2.504      4.301      3.554         11       1024: 100%|██████████| 53/53 [00:26<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  21%|██▏       | 3/14 [00:05<00:21,  1.93s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 740.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 205.12 MiB is free. Including non-PyTorch memory, this process has 3.73 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 569.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/data.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, data\u001b[38;5;241m=\u001b[39mdataset, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/engine/model.py:805\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/engine/trainer.py:432\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/engine/trainer.py:605\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    600\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    Runs validation on test set using self.validator.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    606\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/engine/validator.py:189\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[38;5;241m3\u001b[39m]:\n\u001b[0;32m--> 189\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(preds)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_metrics(preds, batch)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;129;01mand\u001b[39;00m batch_i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/models/yolo/obb/val.py:41\u001b[0m, in \u001b[0;36mOBBValidator.postprocess\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply Non-maximum suppression to prediction outputs.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mnon_max_suppression(\n\u001b[1;32m     42\u001b[0m         preds,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mconf,\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39miou,\n\u001b[1;32m     45\u001b[0m         labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlb,\n\u001b[1;32m     46\u001b[0m         nc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc,\n\u001b[1;32m     47\u001b[0m         multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m         agnostic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39magnostic_nms,\n\u001b[1;32m     49\u001b[0m         max_det\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_det,\n\u001b[1;32m     50\u001b[0m         rotated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/utils/ops.py:288\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rotated:\n\u001b[1;32m    287\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x[:, :\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m c, x[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m4\u001b[39m], x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# xywhr\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m     i \u001b[38;5;241m=\u001b[39m nms_rotated(boxes, scores, iou_thres)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m x[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m c  \u001b[38;5;66;03m# boxes (offset by class)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/utils/ops.py:157\u001b[0m, in \u001b[0;36mnms_rotated\u001b[0;34m(boxes, scores, threshold)\u001b[0m\n\u001b[1;32m    155\u001b[0m sorted_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margsort(scores, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    156\u001b[0m boxes \u001b[38;5;241m=\u001b[39m boxes[sorted_idx]\n\u001b[0;32m--> 157\u001b[0m ious \u001b[38;5;241m=\u001b[39m batch_probiou(boxes, boxes)\u001b[38;5;241m.\u001b[39mtriu_(diagonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    158\u001b[0m pick \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(ious\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m threshold)\u001b[38;5;241m.\u001b[39msqueeze_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sorted_idx[pick]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ultralytics/utils/metrics.py:262\u001b[0m, in \u001b[0;36mbatch_probiou\u001b[0;34m(obb1, obb2, eps)\u001b[0m\n\u001b[1;32m    257\u001b[0m a2, b2, c2 \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _get_covariance_matrix(obb2))\n\u001b[1;32m    259\u001b[0m t1 \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    260\u001b[0m     ((a1 \u001b[38;5;241m+\u001b[39m a2) \u001b[38;5;241m*\u001b[39m (y1 \u001b[38;5;241m-\u001b[39m y2)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m (b1 \u001b[38;5;241m+\u001b[39m b2) \u001b[38;5;241m*\u001b[39m (x1 \u001b[38;5;241m-\u001b[39m x2)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m ((a1 \u001b[38;5;241m+\u001b[39m a2) \u001b[38;5;241m*\u001b[39m (b1 \u001b[38;5;241m+\u001b[39m b2) \u001b[38;5;241m-\u001b[39m (c1 \u001b[38;5;241m+\u001b[39m c2)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m eps)\n\u001b[1;32m    261\u001b[0m ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m--> 262\u001b[0m t2 \u001b[38;5;241m=\u001b[39m (((c1 \u001b[38;5;241m+\u001b[39m c2) \u001b[38;5;241m*\u001b[39m (x2 \u001b[38;5;241m-\u001b[39m x1) \u001b[38;5;241m*\u001b[39m (y1 \u001b[38;5;241m-\u001b[39m y2)) \u001b[38;5;241m/\u001b[39m ((a1 \u001b[38;5;241m+\u001b[39m a2) \u001b[38;5;241m*\u001b[39m (b1 \u001b[38;5;241m+\u001b[39m b2) \u001b[38;5;241m-\u001b[39m (c1 \u001b[38;5;241m+\u001b[39m c2)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m eps)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    263\u001b[0m t3 \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    264\u001b[0m     ((a1 \u001b[38;5;241m+\u001b[39m a2) \u001b[38;5;241m*\u001b[39m (b1 \u001b[38;5;241m+\u001b[39m b2) \u001b[38;5;241m-\u001b[39m (c1 \u001b[38;5;241m+\u001b[39m c2)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m ((a1 \u001b[38;5;241m*\u001b[39m b1 \u001b[38;5;241m-\u001b[39m c1\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m (a2 \u001b[38;5;241m*\u001b[39m b2 \u001b[38;5;241m-\u001b[39m c2\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m+\u001b[39m eps)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;241m+\u001b[39m eps\n\u001b[1;32m    267\u001b[0m )\u001b[38;5;241m.\u001b[39mlog() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    268\u001b[0m bd \u001b[38;5;241m=\u001b[39m (t1 \u001b[38;5;241m+\u001b[39m t2 \u001b[38;5;241m+\u001b[39m t3)\u001b[38;5;241m.\u001b[39mclamp(eps, \u001b[38;5;241m100.0\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 205.12 MiB is free. Including non-PyTorch memory, this process has 3.73 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 569.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "dataset = \"../dataset/data.yaml\"\n",
    "\n",
    "model.train(epochs=1, data=dataset, batch=2)\n",
    "\n",
    "# results = model.val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
